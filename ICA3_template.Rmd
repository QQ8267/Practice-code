---
title: "STAT0006 ICA 3"
subtitle: "Group 5"
author: "Student numbers: 21117235, 20120251, 21026223, 21026576"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
ice_cream <- read.csv("ice_creams.csv")
ice_cream_new <- read.csv("ice_creams_new.csv")
brand_A <- data.frame(subset(ice_cream, subset = ice_cream$brand == 'BrandA'))
brand_B <- data.frame(subset(ice_cream, subset = ice_cream$brand == "BrandB"))
brand_C <- data.frame(subset(ice_cream, subset = ice_cream$brand == "BrandC"))
holi_N <- data.frame(subset(ice_cream, subset = ice_cream$holiday == "N"))
holi_Y <- data.frame(subset(ice_cream, subset = ice_cream$holiday == "Y"))
store_L <- data.frame(subset(ice_cream, subset = ice_cream$store_type == "Large"))
store_M <- data.frame(subset(ice_cream, subset = ice_cream$store_type == "Medium"))
store_S <- data.frame(subset(ice_cream, subset = ice_cream$store_type == "Small"))
out_ice_cream <- data.frame(ice_cream[-c(3,63,113),]) # this is data without possible outliers
out_na_ice_cream <- data.frame(ice_cream[-c(3,63,113,177, 249, 271),]) # this is data without possible outliers and missing observations
```

### Introduction to the data

In this EDA we want to analyse a dataset containing information about a random subset of a large supermarkets chain's weekly sales of a certain type of ice cream across their stores. The goal is to understand what factors affect the number of ice creams sold, in order to help the sales team plan for their future sales in ice cream. 

The data set we have been asked to analyse has been recorded over the last 5 years, which contains 314 observations on 11 different variables including the number of ice creams of a particular brand sold in a store in a single week; there are also three missing data values. The ten other variables consist of the brand of ice cream for which the sales were counted, the number of other ice cream brands available to buy in the store that week, the distance to the nearest other supermarket store (in miles), whether there was a national bank holiday that week, the wholesale price of milk, reported as the national average that week (in pence per litre), whether there was a promotion running on this brand of ice cream that week, the size of the store, average weekly temperature at the store (Celsius), average weekly wind speed at the store (knots), and the year the sales were recorded. 

The average number of ice creams sold in a store in a week is roughly `r round(mean(ice_cream$sales), 0)` and the standard deviation is roughly `r round(sd(ice_cream$sales),0)`. The range of ice creams sold in a week is from `r round(min(ice_cream$sales), 0)` to `r round(max(ice_cream$sales), 0)`. Continuing, we will look at the relationship between sales and the other ten variables in the dataset without taking out the observations that correspond to the missing values. 

<center>
```{r EDA_1, echo=FALSE, fig.cap = "Figure 1: Boxplot comparing number of ice cream sold in a week depdnding on the type of brand. The purple dots show the mean sales in each case. The red dots show possible outliers. "}

boxplot(ice_cream$sales ~ ice_cream$brand, 
        main = "Comparing sales and brand", xlab = "Type of brand", ylab = "Sales",
        names = c("Brand A", "Brand B", "Brand C"))
points(c(mean(brand_A$sales),mean(brand_B$sales), 
         mean(brand_C$sales)), 
       pch = 16, col = "darkorchid", cex=1.25)
points(brand_A$sales[c(3)], col = "red", pch=19)
points(brand_A$sales[c(63)], col = "red", pch=19)
points(brand_A$sales[c(113)], col = "red", pch=19)
```
</center>


From figure 1, the number of ice cream sold for Brand A is the highest with roughly `r round(mean(brand_A$sales),0)` followed by Brand B with average sales of `r round(mean(brand_B$sales),0)` and Brand C has the fewest average sales of `r round(mean(brand_C$sales),0)`. The red points are plausible outliers that are continued to be shown each on the following graphs corresponding to the same three observations which will be further discussed later in the EDA. 

<center>
```{r EDA_2, echo=FALSE, fig.cap = "Figure 2: Boxplot comparing number of ice cream sold in a week and the number of other ice cream brands available to buy in the store that week. The orange dots show the mean sales in each case. The red dots show the same possible outliers."}

boxplot(ice_cream$sales ~ ice_cream$brand_competitors, 
        main = "Comparing sales and brand competitors", xlab = "Number of brand competitors", ylab = "Sales")
points(c(mean(ice_cream$sales[ice_cream$brand_competitors == "3"]),
         mean(ice_cream$sales[ice_cream$brand_competitors == "4"] ), 
         mean(ice_cream$sales[ice_cream$brand_competitors == "5"]), 
         mean(ice_cream$sales[ice_cream$brand_competitors == "6"]), 
         mean(ice_cream$sales[ice_cream$brand_competitors == "7"]), 
         mean(ice_cream$sales[ice_cream$brand_competitors == "8"]),
         mean(ice_cream$sales[ice_cream$brand_competitors == "9"])), 
       pch=16, col = "darkorange", cex=1.25)
points(4, ice_cream$sales[c(3)], col="red", pch=19)
points(7, ice_cream$sales[c(63)], col="red", pch=19)
points(4, ice_cream$sales[c(113)], col="red", pch=19)

```
</center>

From figure 2, comparing `sales` and `brand_competitors` there is a slight increase in ice cream sales as the number of brand competitors increase. The mean sales of ice cream when there are 3 brand competitors is roughly `r round(mean(ice_cream$sales[ice_cream$brand_competitors == "3"]),0)` while when there are 9 brand competitors the average sales is roughly `r round(mean(ice_cream$sales[ice_cream$brand_competitors == "9"]),0)`. 

<center>
```{r EDA_3, echo=FALSE, fig.cap = "Figure 3: Scatter plot comparing number of ice cream sold in a week and the distance to the nearest other supermarket store (miles). The red dots show the same possible outliers."}

plot(ice_cream$distance, ice_cream$sales, 
     main = "Comparing sales and distance", xlab = "Distance (miles)", ylab = "Sales")
points(ice_cream$distance[c(3,63,113)], ice_cream$sales[c(3,63,113)], col = "red", pch=19)
```
</center>

Figure 3 shows that there is a moderate positive linear relationship between `sales` and `distance`. From 0 to 3 miles the ice cream sales increase positively linearly. However, after 3 miles the sales stop increasing linearly and there seems to be no distinct relationship between distance and sales.

<center>
```{r EDA_4, echo=FALSE, fig.cap = "Figure 4: Boxplots to compare the number of ice cream sold in a week and whether there was a national bank holiday during this week. The blue dots show the mean sales in each case while the red dots show the same possible outliers."}

boxplot(ice_cream$sales ~ ice_cream$holiday, 
        main = "Comparing sales and holiday", xlab = "National bank holiday", ylab = "Sales", 
        names = c("No", "Yes"))
points(c(mean(holi_N$sales), mean(holi_Y$sales)), 
       pch = 16, col  = "steelblue2", cex = 1.25)
points(2, ice_cream$sales[c(3)], col="red", pch=19)
points(2, ice_cream$sales[c(63)], col="red", pch=19)
points(2, ice_cream$sales[c(113)], col="red", pch=19)

```
</center>

From figure 4 the range and mean ice cream sales in a week is larger when there is a national bank holiday. 

<center>
```{r EDA_5, echo=FALSE, fig.cap = "Figure 5: Scatter plot comparing the relationship between number of ice cream sold in a week and the wholsale price of milk (pence per litre). The red outliers show the same possible outliers."}

plot(ice_cream$milk, ice_cream$sales, 
     main = "Comparing sales and price of wholesale milk", xlab = "Price", ylab = "Sales")
points(ice_cream$milk[c(3,63,113)], ice_cream$sales[c(3,63,113)], col = "red", pch=19)

```
</center>

From figure 5, in general price of whole sale milk doesn't appear to significantly influence ice cream sales in a single week. 

<center>
```{r EDA_6, echo=FALSE, fig.cap = "Figure 6: Boxplots comparing the number of ice cream sold in a week and whether there was a promotion running on each brand that week. Leftmost plot for Brand A, middle plot for Brand B and right plot for Brand C. The pink dots show the mean sales in each case while the red dots show the same possible outliers."}

par(mfrow = c(1,3))
boxplot(brand_A$sales~ brand_A$promotion, 
        main = "Comparing sales and promotion for Brand A", xlab = "Promotion", ylab = "Sales", 
        names = c("No", "Yes"), cex.main = 0.9)
points(c(mean(brand_A$sales[brand_A$promotion == "N"]), 
         brand_A$sales[brand_A$promotion == "Y"]), 
       pch =16, col = "deeppink3", cex = 1.5)
points(1, ice_cream$sales[c(3)], col="red", pch=19)
points(1, ice_cream$sales[c(63)], col="red", pch=19)
points(1, ice_cream$sales[c(113)], col="red", pch=19)
boxplot(brand_B$sales~ brand_B$promotion, 
        main = "Comparing sales and promotion for Brand B", xlab = "Promotion", ylab = "Sales", 
        names = c("No", "Yes"), cex.main = 0.9)
points(c(mean(brand_B$sales[brand_B$promotion == "N"]), 
         mean(brand_B$sales[brand_B$promotion == "Y"])), 
       pch = 16, col = "deeppink3", cex = 1.5)
boxplot(brand_C$sales~ brand_C$promotion, 
        main = "Comparing sales and promotion for Brand C", xlab = "Promotion", yalb = "Sales", 
        names = c("No", "Yes"), cex.main = 0.9)
points(c(mean(brand_C$sales[brand_C$promotion == "N"]), 
         mean(brand_C$sales[brand_C$promotion == "Y"])), 
       pch = 16, col = "deeppink3", cex = 1.5)
```
</center>

Figure 6 shows that for all brands of ice cream, a promotion running on the respective brand appears to increase that brands ice cream sales. In particular, Brand C has highest increase in average ice cream sales when there is a promotion for its brand, followed by Brand B then Brand A. 

<center>
```{r EDA_7, echo=FALSE, fig.cap = "Figure 7: Boxplots comparing the number of ice creams sold in a single week with the size of the store. The blue dots show the mean sales for each case. The red dots show the same possible outliers."}

boxplot(ice_cream$sales ~ ice_cream$store_type, main  = "Comparing sales and size of store", xlab = "Size of store", ylab = "Sales")
points(c(mean(store_L$sales), 
         mean(store_M$sales),
         mean(store_S$sales)),
       pch = 16, col = "blue", cex = 1.25)
points(1, ice_cream$sales[c(3)], col="red", pch=19)
points(1, ice_cream$sales[c(63)], col="red", pch=19)
points(1, ice_cream$sales[c(113)], col="red", pch=19)
```
</center>

From figure 7 it is apparent that large supermarkets have the highest average sales with roughly mean `r round(mean(store_L$sales),0)`, followed by mediums stores with average sales of roughly `r round(mean(store_M$sales),0)`, and then small stores with average ice cream sales of roughly `r round(mean(store_S$sales),0)`. 

<center>
```{r EDA_8, echo=FALSE, fig.cap = "Figure 8: Left plot shows scatterplot comparing relationship between number of ice creams sold in single week and average weekly temperature in store (Celsius). The right scatterplot compares the relationship between number of ice cream sold in a week and the average weekly wind speed at store (knots). The red dots show the same possible outliers."}

par(mfrow=c(1,2))
plot(ice_cream$temperature, ice_cream$sales, main = "Comparing sales and temperature", xlab = "Average weekly temperature (Celsius)", ylab = "Sales", cex.main = 1.1)
points(ice_cream$temperature[c(3,63,113)], ice_cream$sales[c(3,63,113)], col = "red", pch=19)
plot(ice_cream$wind, ice_cream$sales, main = "Comparing sales and wind", xlab = "Average weekly wind speed (knots)", ylab = "Sales", cex.main = 1.1)
points(ice_cream$wind[c(3,63,113)], ice_cream$sales[c(3,63,113)], col = "red", pch=19)
```
</center>

The left plot in figure 8 shows a positive linear relationship between average weekly temperature at the store and ice cream sales in a week. Thus the higher the temperature in the store, the more ice cream sales there are in the single week. The right plot shows that in general there doesn't seem to appear to be a relationship between average weekly wind speed at the store and the number of ice creams sold in a week.

<center>
```{r EDA_9, echo=FALSE, fig.cap = "Figure 9: Boxplot comparing ice cream sales and the year sold. The purple dots showcase the mean sales in each case while the red dots show the same possible outliers."}

boxplot(ice_cream$sales ~ ice_cream$year, main = "Comparing sales and year", xlab = "Year", ylab = "Sales")
points(c(mean(ice_cream$sales[ice_cream$year == "2018"]), 
         mean(ice_cream$sales[ice_cream$year == "2019"]), 
         mean(ice_cream$sales[ice_cream$year == "2020"]), 
         mean(ice_cream$sales[ice_cream$year == "2021"]),
         mean(ice_cream$sales[ice_cream$year == "2022"])), 
       pch = 16, col = "mediumorchid3", cex = 1.25)
points(1, ice_cream$sales[c(3)], col="red", pch=19)
points(3, ice_cream$sales[c(63)], col="red", pch=19)
points(5, ice_cream$sales[c(113)], col="red", pch=19)
```
</center>

From figure 9 the boxplots show that the range of ice cream sales in a single week was largest in 2021 compared to the other 4 years. However, the median ice cream sales appear to be roughly similar for all five years. 


From our plots it is apparent that there may be three outliers corresponding to data rows of 3, 63 and 113 highlighted by the red points for all covariates against `sales`. We can plot some of these graphs again with these three points removed. 

<center>
```{r outliers, echo=FALSE, fig.cap = "Figure 10: Scatterplots for temperature, wind, distance and milk covariates plotted against sales without found possible outliers."}
out_ice_cream <- data.frame(ice_cream[-c(3,63,113),])
par(mfrow=c(2,2))

plot(out_ice_cream$temperature, out_ice_cream$sales, main = "Comparing sales and temperature", xlab = "Average weekly temperature (Celsius)", ylab = "Sales", cex.main = 1.1)
plot(out_ice_cream$wind, out_ice_cream$sales, main = "Comparing sales and wind", xlab = "Average weekly wind speed (knots)", ylab = "Sales", cex.main = 1.1)
plot(out_ice_cream$distance, out_ice_cream$sales, 
     main = "Comparing sales and distance", xlab = "Distance (miles)", ylab = "Sales")
plot(out_ice_cream$milk, out_ice_cream$sales,
     main = "Comparing sales and price of wholesale milk", xlab = "Price", ylab = "Sales", cex.main = 1)
```
</center>

To conclude 8 of the variables in our dataset appear to be related to the number of ice creams of a particular brand sold in a store in a single week that are worth considering when building our model.

### Model building 

We will begin by building Model 1 that includes all covariates and observations in our model using `sales` as our response variable. 

**Model 1: **
```{r model_1, echo=FALSE}

model_1 <- lm(sales ~ as.factor(brand) + brand_competitors + distance + as.factor(holiday) + milk + as.factor(promotion) + as.factor(store_type) + temperature + wind + as.factor(year), data = ice_cream) 
summary(model_1)
```

To confirm our speculation about the three outliers we can plot a scatter plot of the standardised residuals against fitted values for the first model. We can observe from Figure 11 that there does seem to appear to be three outliers that correspond to the same points found in the EDA. In addition, due to the three missing observations in our EDA, we will continue to remove these outliers and missing observations when building our next models, starting from Model 2. 

<center>
```{r model1_out, echo=FALSE, fig.cap="Figure 11: Standardised residuals against fitted values for Model 1"}
model1_stdres <-rstandard(model_1)
model1_fitted <- fitted(model_1)

plot(model1_fitted, model1_stdres, xlab = "Fitted values", ylab = "Standardised residuals", main = "Standardized residuals against fitted values")
abline(0,0)
```
</center>

**Model 2: **
```{r model_2, echo=FALSE}
model_2<- lm(sales ~ as.factor(brand) + brand_competitors + distance + as.factor(holiday) + milk + as.factor(promotion) + as.factor(store_type) + temperature + wind + as.factor(year), data = out_na_ice_cream)
summary(model_2)
```

In Model 2, we have removed three observations, corresponding to the found outliers, where 16 regression coefficients have been estimated which inlcudes one estimated intercept. From our EDA it was noticed that `wind` and `milk` do not have a strong relationship with ice cream sales and thus we will perform two t tests to check whether these covariates should be removed from our regression. 

Using Model 2 our hypotheses are:
$$
\text{Hypotheses for milk} \begin{cases} H_0:\beta_6 = 0\\ H_A:\beta_6 \ne 0 \end{cases}
$$

$$
\text{Hypotheses for wind} \begin{cases}H_0:\beta_{11} = 0\\ H_A:\beta_{11} \ne 0 \end{cases}
$$
From model 2, our p-value for `milk` is large at value 0.329, we have no evidence to reject the null hypothesis showing that we prefer the model without this covariate. In addition, we see that our p-value for `wind` from our t statistic is large at the value 0.983 showing that we have no evidence to reject the null hypothesis and that we prefer the regression model without this covariate as well. 

Furthermore, in our EDA `year` did not appear to be strongly related to ice cream sales in a week. So we will conduct a F-test to check whether this covariate should be included in our model or not. Following, we will create a nested model, called Model 3, without the `year` covariate.

**Model 3: **
```{r model_3, echo=FALSE}
model_3<- lm(sales ~ as.factor(brand) + brand_competitors + distance + as.factor(holiday) + as.factor(promotion) + as.factor(store_type) + temperature + as.factor(year), data = out_na_ice_cream)
summary(model_3)
```

Our hypothesis is:

$$
\text{Hypotheses for year} \begin{cases} H_0:\beta_{10} = \beta_{11} = \beta_{12} = \beta_{13} = 0\\ H_A:\text{At least one of }  \beta_{10}, \beta_{11}, \beta_{12} \text{ and } \beta_{13} \text{ is not equal to } 0 \end{cases}
$$

```{r model_4, echo=FALSE}
model_4 <- lm(sales ~as.factor(brand) + brand_competitors + distance + as.factor(holiday) + as.factor(promotion) + as.factor(store_type) + temperature, data = out_na_ice_cream)
```

```{r anova, echo=FALSE}
anova(model_4, model_3, test = "F")
```

From the ANOVA results the p-value from the F-statistic is large suggesting that we have no evidence to reject the null. Concluding that the model without `year` is better. 


<!-- **Model 5: **  -->
```{r model_5, echo=FALSE}

model_5 <- lm(sales ~ as.factor(brand) + brand_competitors + distance + as.factor(holiday) + as.factor (promotion) + as.factor(store_type) + temperature, data = out_na_ice_cream)
```

**Adding interactions: ** 

We will now look at adding interactions between the covariates. We noticed that small store types are estimated to have higher sales than medium, large stores with the same distances. Therefore, it may be interesting to observe whether the number of ice cream sales increases or decreases at a different rate with distance to the nearest supermarket depending what size of store the consumer is at. 

Following, we will conduct a F-test to check whether the interaction covariate should be included into the model or not. 


```{r model_6, echo=FALSE}

model_6 <- lm(sales ~ as.factor(brand) + brand_competitors + distance + as.factor(holiday) + as.factor (promotion) + as.factor(store_type) + temperature + distance*as.factor(store_type), data = out_na_ice_cream)

anova(model_5, model_6, test = "F")
```
Using ANOVA to compare our two models, one with an interaction between `distance` and `store_type`, the F-test results in a small p-value indicating that we have strong evidence against the null hypothesis that the interaction should be excluded from the regression. Therefore, we prefer the model with the interaction between these covariates, calling it Model 6. 

**Model 6: ** 
```{r model_6_cont, echo=FALSE}
summary(model_6)
```


We could also analyse the interaction between `distance` and `brand`. This would allow us to observe whether the sales of ice cream depends on how far the nearest supermarket is when considering the specific brand of ice cream for which the sales are being counted. Thus we create Model 7 including an interaction between these two covariates. 

<!-- **Model 7: ** -->
```{r model_7, echo=FALSE}

model_7 <- lm(sales ~ as.factor(brand) + brand_competitors + distance + as.factor(holiday) + as.factor (promotion) + as.factor(store_type) + temperature + distance*as.factor(store_type) + distance*as.factor(brand), data = out_na_ice_cream)
```

Following, we will perform an F-test to examine if we should include this interaction in our regression model. 
```{r anova_7, echo=FALSE}
anova(model_6, model_7, test = "F")
```

From the ANOVA test and the corresponding small p-value it is prevalent that we have evidence to reject the null hypothesis. Accordingly, we can include  the interaction between `distance` and `brand_competitors` in our linear regression model. 


It may be further interesting to look at the interaction between the the brand of ice cream for which sales are being counted and the the number of other ice cream brands available to buy in the store that week. This would allow the observation of how ice cream sales of a particular brand increase or decrease at a different rate with brand competitors depending on which brand sales are being counted. Following model 8 is created with the interaction between these two covariates. 

**Model 8: **
```{r model_8, echo=FALSE}

model_8 <- lm(sales ~ as.factor(brand) + brand_competitors + distance + as.factor(holiday) + as.factor (promotion) + as.factor(store_type) + temperature + distance*as.factor(store_type) + distance*as.factor(brand) + brand_competitors*as.factor(brand), data = out_na_ice_cream)
summary(model_8)
```

To check whether this interaction helps improve our model we will perform another F-test where the null hypothesis is whether the interaction coefficients equal 0. 

```{r anova_8, echo=FALSE}
anova(model_7, model_8, test = "F")
```

From the F-statistic the resulting p-value is small suggesting that we have evidence to reject the null hypothesis. Accordingly, we can include the interaction between `brand` and `brand_competitors` in our linear regression model. 


<center>
```{r model8_lev, echo=FALSE, fig.cap="Figure x: Standardised residuals against fitted values for Model 8"}
model8_stdres <-rstandard(model_8)
model8_fitted <- fitted(model_8)
model8_fitted_d <- data.frame(fitted(model_8))
plot(model8_fitted, model8_stdres, xlab = "Fitted values", ylab = "Standardised residuals", main = "Standardized residuals against fitted values")
abline(0,0)
```
</center>

### Model checking for final chosen model

First, we check linearity by plotting `brand_competitors`, `distance` and `temperature` each against the standardised residuals. 

<center>
```{r linearity, echo=FALSE}
par(mfrow=c(1,3))
plot(out_na_ice_cream$brand_competitors, model8_stdres, xlab = "Number of brand competitors", ylab = "Standardised residuals")
abline(0,0)
plot(out_na_ice_cream$distance, model8_stdres, xlab = "Distance", ylab = "Standardised residuals")
abline(0,0)
plot(out_na_ice_cream$temperature, model8_stdres, xlab = "Temperature (Celsius)", ylab = "Standardised residuals")
abline (0,0)
```
</center>



Second, we check normality of error terms using a QQ-plot
<center>
```{r qqplot, echo=FALSE}
qqnorm(model8_stdres, main = "QQ-plot", ylab = "Standardised Residuals", xlab = "Quantiles of N(0,1)")
qqline(model8_stdres, col = "red")
```
</center>



Third, we will check the homoscedasticity of the error term but plotting the standardised residuals against the fitted values. 
<center>
```{r homo, echo=FALSE}
plot(model8_fitted, model8_stdres, xlab = "Fitted values", ylab = "Standardised residuals")
abline(0,0)
```
</center>
There is some evidence against the homoscedasticity assumption here. 

model8 <- lm(formula = sqrt(sales) ~ as.factor(brand) + brand_competitors + distance + as.factor(holiday) + as.factor(promotion) + as.factor(store_type) + temperature + distance * as.factor(store_type) + distance* as.factor(brand) + brand_competitors * as.factor(brand) +distance * as.factor(holiday), data = out_na_ice_cream)

summary(model8)


predict(model8, data.frame(ice_creams_new[1,]), interval="prediction")
predict(model8, data.frame(ice_creams_new[2,]), interval="prediction")

